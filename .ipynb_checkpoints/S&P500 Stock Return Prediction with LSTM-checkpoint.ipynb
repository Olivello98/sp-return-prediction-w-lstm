{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, LSTM, Dense\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "from tensorflow.keras import backend\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import cufflinks as cf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "The following code is for illustrative purposes. The function`download_data` scrapes data from Yahoo Finance. The actual call of the function `download_data()` is hashed by default. You should load data directly from csv file by running subsequent cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    '''\n",
    "    ***Code to download data from yfinance*** \n",
    "    Do not run unless you want to see the working logic. Instead, load data directly from the csv.\n",
    "    '''\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "    tickers = [s.replace('\\n', '') for s in tickers]\n",
    "    \n",
    "    \n",
    "    # s&p500 components\n",
    "    start = datetime.datetime(2000,1,1)\n",
    "    end = datetime.datetime(2020,5,29)\n",
    "\n",
    "    price_data = yf.download(tickers=tickers, start=start, end=end)[\"Adj Close\"]\n",
    "    volume_data = yf.download(tickers=tickers, start=start, end=end)[\"Volume\"]\n",
    "        \n",
    "    \n",
    "    price_data.columns = sorted(price_data.columns)\n",
    "    volume_data.columns = sorted(volume_data.columns)\n",
    "    price_data.to_csv(\"price_data.csv\")\n",
    "    volume_data.to_csv(\"volume_data.csv\")\n",
    "    \n",
    "    \n",
    "\n",
    "# download_data()   ### <-- do not run this ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load and cleaning\n",
    "Data comprises S&P500 components' daily prices and volumes from January 2000 to May 2020. Companies with no data available on 02/01/2000 were removed. Forward fill was used to impute (rare) missings in the middle of the dataset. Daily log-returns and flows are easily computed from prices and volumes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Any Nans left? False for returns, False for flows\n",
      "returns shape: (5132, 375), flows shape: (5132, 375)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "prices = pd.read_csv('price_data.csv', index_col = \"Date\", parse_dates=True, \n",
    "                     ).dropna(axis = 1, how = 'all').dropna(axis=0, how=\"all\")\n",
    "\n",
    "volumes = pd.read_csv('volume_data.csv', index_col = \"Date\", parse_dates=True, \n",
    "                    ).dropna(axis = 1, how = 'all').dropna(axis=0, how=\"all\")\n",
    "\n",
    "# download s&p 500 data to make benchmark later on\n",
    "snp = yf.download(\"^GSPC\", start=prices.index[0], end=prices.index[-1])[[\"Adj Close\"]]\n",
    "\n",
    "# drop columns of stocks that did not exist at starting date\n",
    "frp, frv = prices.iloc[0,:], volumes.iloc[0,:] #first row\n",
    "p_idx_existing = [i for i in range(len(frp.isna())) if not frp.isna()[i]]\n",
    "v_idx_existing = [i for i in range(len(frv.isna())) if not frv.isna()[i]]\n",
    "prices = prices.iloc[:, np.r_[p_idx_existing]]\n",
    "volumes = volumes.iloc[:, np.r_[v_idx_existing]]\n",
    "\n",
    "# forward-fill missing values\n",
    "prices.fillna(axis = 0, method=\"ffill\", inplace=True)\n",
    "volumes.fillna(axis = 0, method=\"ffill\", inplace=True)\n",
    "\n",
    "# compute log-returns and flows (change in volumes)\n",
    "returns   = np.log(prices/prices.shift(1)).dropna(axis=0, how=\"all\")\n",
    "flows = (volumes - volumes.shift(1)).dropna(axis=0, how=\"all\")\n",
    "\n",
    "# compute log-returns for s&p500\n",
    "snp_ret = np.log(snp/snp.shift(1)).dropna(axis=0, how=\"all\")\n",
    "\n",
    "# check if any NaNs left\n",
    "print(\"Any Nans left? {} for returns, {} for flows\".format(returns.isna().any().any(), \n",
    "                                                           flows.isna().any().any()))\n",
    "\n",
    "# 2 stocks have no flow data available, so we remove them\n",
    "returns =  returns[flows.columns]\n",
    "\n",
    "# rename columns\n",
    "returns.columns = returns.columns + \"_r\"\n",
    "flows.columns = flows.columns + \"_flow\"\n",
    "\n",
    "#check shape\n",
    "print(\"returns shape: {}, flows shape: {}\".format(returns.shape, flows.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset includes daily stock returns (and flows) for 375 different stocks observed over 5132 consecutive (trading) days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "We want to make rolling 1-day-ahead return forecasts using the entire crosssection of lagged returns, lagged volume flows, 20-day look-back volatilities and 5-day-, 20-day-,  and 250-day-lookback cumulative returns as predictors, inspired by Chinco, Clark-Joseph, Ye (2019). Their rational is that \"cross-section of lagged returns contains a sparse collection of signals\" that can be applied to make look-ahead predictions. We modify their intraday approach to a lower frequency environment, using daily returns. Moreover, we add the aforesaid additional features, taking a data-driven approach. The following cells define the appropriate functions to \"engineer\" the aforesaid features from the available ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# define functions for data engineering\n",
    "# build dataset with n-lag returns for each feature\n",
    "def lags_builder(dataset, n_lags):\n",
    "    # function to add lags\n",
    "    cache = []\n",
    "    for i in range(n_lags):\n",
    "        lag_df = dataset.shift(i+1)\n",
    "        lag_df.columns = dataset.columns.map(lambda x : x+'_lag_'+str(i+1))\n",
    "        cache.append(lag_df)\n",
    "    dataset_with_lags = pd.concat(cache, axis=1)\n",
    "    return dataset_with_lags\n",
    "\n",
    "# build dataset with look-back volatility for each feature\n",
    "def rolling_lag_volatility_builder(dataset, look_back_window):\n",
    "    volatility_df = dataset.rolling(look_back_window).apply(lambda x: np.nanstd(x))\n",
    "    old_col = list(volatility_df.columns)\n",
    "    for i in range(len(old_col)):\n",
    "        old_col[i] = old_col[i].replace(\"_r_lag_1\",'_std_'+str(look_back_window))\n",
    "    volatility_df.columns = old_col\n",
    "    return volatility_df\n",
    "\n",
    "# build dataset with look-back cumulative return for each feature\n",
    "def rolling_lag_cumreturn_builder(dataset, look_back_window):\n",
    "    cum_ret_df = dataset.rolling(look_back_window).apply(lambda x: np.nansum(x))\n",
    "    old_col = list(cum_ret_df.columns)\n",
    "    for i in range(len(old_col)):\n",
    "        old_col[i] = old_col[i].replace(\"_r_lag_1\",'_mom_'+str(look_back_window))\n",
    "    cum_ret_df.columns = old_col\n",
    "    return cum_ret_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is for illustrative purposes and takes long to run, thus code is hashed by default. You can either un-hash and run it or load data that already includes engineered features by running subsequent cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# clean data, generate interesting features. NB: ***do not run unless you want to see the working logic***\n",
    "# generate 1-day lag returns, 1-day lag flows, 20-day look-back rolling volatility, 5-day, 20-day, 250-day look-back returns \n",
    "\n",
    "returns_1_lags  = lags_builder(returns, 1)\n",
    "flows_1_lags    = lags_builder(flows, 1)\n",
    "vols_20         = rolling_lag_volatility_builder(returns_1_lags, 20)\n",
    "cum_returns_5   = rolling_lag_cumreturn_builder(returns_1_lags, 5)\n",
    "cum_returns_20  = rolling_lag_cumreturn_builder(returns_1_lags, 20)\n",
    "cum_returns_250 = rolling_lag_cumreturn_builder(returns_1_lags, 250)\n",
    "\n",
    "# concatenate dataframe making stock returns in first 100 columns as dependent variables\n",
    "data = pd.concat([returns, returns_1_lags, flows_1_lags, vols_20, cum_returns_5, \n",
    "                  cum_returns_20, cum_returns_250 ], axis = 1).iloc[250:,:]\n",
    "\n",
    "pickle.dump(data, open(\"data_engineered.pkl\", \"wb\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with engineered features using .pkl file\n",
    "data = pickle.load(open(\"data_engineered.pkl\", \"rb\" ))\n",
    "y_columns = data.columns[:375]\n",
    "x_columns = data.columns[375:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_r</th>\n",
       "      <th>AAPL_r</th>\n",
       "      <th>ABC_r</th>\n",
       "      <th>ABMD_r</th>\n",
       "      <th>ABT_r</th>\n",
       "      <th>ADBE_r</th>\n",
       "      <th>ADI_r</th>\n",
       "      <th>ADM_r</th>\n",
       "      <th>ADP_r</th>\n",
       "      <th>ADSK_r</th>\n",
       "      <th>...</th>\n",
       "      <th>WST_r</th>\n",
       "      <th>WY_r</th>\n",
       "      <th>XEL_r</th>\n",
       "      <th>XLNX_r</th>\n",
       "      <th>XOM_r</th>\n",
       "      <th>XRAY_r</th>\n",
       "      <th>XRX_r</th>\n",
       "      <th>YUM_r</th>\n",
       "      <th>ZBRA_r</th>\n",
       "      <th>ZION_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-29</th>\n",
       "      <td>-0.010221</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>-0.041218</td>\n",
       "      <td>-0.040410</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.057397</td>\n",
       "      <td>-0.053488</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.016375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017654</td>\n",
       "      <td>-0.024332</td>\n",
       "      <td>-0.002148</td>\n",
       "      <td>-0.051497</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>-0.085679</td>\n",
       "      <td>-0.077961</td>\n",
       "      <td>-0.013171</td>\n",
       "      <td>-0.074163</td>\n",
       "      <td>0.006024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>-0.073406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011202</td>\n",
       "      <td>-0.074901</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>-0.218967</td>\n",
       "      <td>-0.085348</td>\n",
       "      <td>-0.025318</td>\n",
       "      <td>-0.019941</td>\n",
       "      <td>-0.047515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002548</td>\n",
       "      <td>-0.012392</td>\n",
       "      <td>-0.026145</td>\n",
       "      <td>-0.064358</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>0.102654</td>\n",
       "      <td>-0.032726</td>\n",
       "      <td>0.037953</td>\n",
       "      <td>-0.040864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>0.098210</td>\n",
       "      <td>0.096074</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.090247</td>\n",
       "      <td>-0.022325</td>\n",
       "      <td>0.214885</td>\n",
       "      <td>0.148053</td>\n",
       "      <td>-0.043675</td>\n",
       "      <td>-0.021375</td>\n",
       "      <td>0.063678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>-0.035959</td>\n",
       "      <td>0.166053</td>\n",
       "      <td>-0.044452</td>\n",
       "      <td>-0.052644</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.055199</td>\n",
       "      <td>0.102258</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A_r    AAPL_r     ABC_r    ABMD_r     ABT_r    ADBE_r  \\\n",
       "Date                                                                     \n",
       "2000-12-29 -0.010221  0.004211 -0.041218 -0.040410 -0.001289 -0.057397   \n",
       "2001-01-02 -0.073406  0.000000 -0.011202 -0.074901 -0.006473 -0.218967   \n",
       "2001-01-03  0.098210  0.096074  0.019828  0.090247 -0.022325  0.214885   \n",
       "\n",
       "               ADI_r     ADM_r     ADP_r    ADSK_r  ...     WST_r      WY_r  \\\n",
       "Date                                                ...                       \n",
       "2000-12-29 -0.053488  0.025318 -0.000986  0.016375  ... -0.017654 -0.024332   \n",
       "2001-01-02 -0.085348 -0.025318 -0.019941 -0.047515  ... -0.002548 -0.012392   \n",
       "2001-01-03  0.148053 -0.043675 -0.021375  0.063678  ...  0.040005  0.024632   \n",
       "\n",
       "               XEL_r    XLNX_r     XOM_r    XRAY_r     XRX_r     YUM_r  \\\n",
       "Date                                                                     \n",
       "2000-12-29 -0.002148 -0.051497  0.000720 -0.085679 -0.077961 -0.013171   \n",
       "2001-01-02 -0.026145 -0.064358  0.024850 -0.003200  0.102654 -0.032726   \n",
       "2001-01-03 -0.035959  0.166053 -0.044452 -0.052644  0.024097  0.055199   \n",
       "\n",
       "              ZBRA_r    ZION_r  \n",
       "Date                            \n",
       "2000-12-29 -0.074163  0.006024  \n",
       "2001-01-02  0.037953 -0.040864  \n",
       "2001-01-03  0.102258  0.032824  \n",
       "\n",
       "[3 rows x 375 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_r_lag_1</th>\n",
       "      <th>AAPL_r_lag_1</th>\n",
       "      <th>ABC_r_lag_1</th>\n",
       "      <th>ABMD_r_lag_1</th>\n",
       "      <th>ABT_r_lag_1</th>\n",
       "      <th>ADBE_r_lag_1</th>\n",
       "      <th>ADI_r_lag_1</th>\n",
       "      <th>ADM_r_lag_1</th>\n",
       "      <th>ADP_r_lag_1</th>\n",
       "      <th>ADSK_r_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>WST_mom_250</th>\n",
       "      <th>WY_mom_250</th>\n",
       "      <th>XEL_mom_250</th>\n",
       "      <th>XLNX_mom_250</th>\n",
       "      <th>XOM_mom_250</th>\n",
       "      <th>XRAY_mom_250</th>\n",
       "      <th>XRX_mom_250</th>\n",
       "      <th>YUM_mom_250</th>\n",
       "      <th>ZBRA_mom_250</th>\n",
       "      <th>ZION_mom_250</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-29</th>\n",
       "      <td>-0.011236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>-0.024451</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>-0.060982</td>\n",
       "      <td>-0.028524</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.068319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162042</td>\n",
       "      <td>-0.263985</td>\n",
       "      <td>0.488924</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>0.146496</td>\n",
       "      <td>0.603236</td>\n",
       "      <td>-1.563024</td>\n",
       "      <td>-0.109651</td>\n",
       "      <td>-0.248148</td>\n",
       "      <td>0.132055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>-0.010221</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>-0.041218</td>\n",
       "      <td>-0.040410</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.057397</td>\n",
       "      <td>-0.053488</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.016375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189973</td>\n",
       "      <td>-0.250027</td>\n",
       "      <td>0.464011</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.166556</td>\n",
       "      <td>0.517557</td>\n",
       "      <td>-1.593357</td>\n",
       "      <td>-0.102516</td>\n",
       "      <td>-0.307777</td>\n",
       "      <td>0.187714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>-0.073406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011202</td>\n",
       "      <td>-0.074901</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>-0.218967</td>\n",
       "      <td>-0.085348</td>\n",
       "      <td>-0.025318</td>\n",
       "      <td>-0.019941</td>\n",
       "      <td>-0.047515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188423</td>\n",
       "      <td>-0.314037</td>\n",
       "      <td>0.400007</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>0.138324</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>-1.540912</td>\n",
       "      <td>-0.140358</td>\n",
       "      <td>-0.288788</td>\n",
       "      <td>0.148034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A_r_lag_1  AAPL_r_lag_1  ABC_r_lag_1  ABMD_r_lag_1  ABT_r_lag_1  \\\n",
       "Date                                                                          \n",
       "2000-12-29  -0.011236      0.000000     0.015560     -0.024451    -0.001288   \n",
       "2001-01-02  -0.010221      0.004211    -0.041218     -0.040410    -0.001289   \n",
       "2001-01-03  -0.073406      0.000000    -0.011202     -0.074901    -0.006473   \n",
       "\n",
       "            ADBE_r_lag_1  ADI_r_lag_1  ADM_r_lag_1  ADP_r_lag_1  ADSK_r_lag_1  \\\n",
       "Date                                                                            \n",
       "2000-12-29     -0.060982    -0.028524     0.021599     0.008915      0.068319   \n",
       "2001-01-02     -0.057397    -0.053488     0.025318    -0.000986      0.016375   \n",
       "2001-01-03     -0.218967    -0.085348    -0.025318    -0.019941     -0.047515   \n",
       "\n",
       "            ...  WST_mom_250  WY_mom_250  XEL_mom_250  XLNX_mom_250  \\\n",
       "Date        ...                                                       \n",
       "2000-12-29  ...    -0.162042   -0.263985     0.488924      0.038038   \n",
       "2001-01-02  ...    -0.189973   -0.250027     0.464011      0.009530   \n",
       "2001-01-03  ...    -0.188423   -0.314037     0.400007     -0.032696   \n",
       "\n",
       "            XOM_mom_250  XRAY_mom_250  XRX_mom_250  YUM_mom_250  ZBRA_mom_250  \\\n",
       "Date                                                                            \n",
       "2000-12-29     0.146496      0.603236    -1.563024    -0.109651     -0.248148   \n",
       "2001-01-02     0.166556      0.517557    -1.593357    -0.102516     -0.307777   \n",
       "2001-01-03     0.138324      0.497217    -1.540912    -0.140358     -0.288788   \n",
       "\n",
       "            ZION_mom_250  \n",
       "Date                      \n",
       "2000-12-29      0.132055  \n",
       "2001-01-02      0.187714  \n",
       "2001-01-03      0.148034  \n",
       "\n",
       "[3 rows x 2250 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display targets, i.e., returns to be predicted\n",
    "display(data[y_columns].head(3))\n",
    "\n",
    "# display predictors \n",
    "display(data[x_columns].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "Train / Validation / Test split of data is 70/10/20. Moreover, data is scaled to values between $[-1,1]$. Finally, predictor matrices for train, test and validation sets are reshaped to account for input requirements for recurrent neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3417, 1, 2250) (489, 2625) (976, 1, 2250)\n"
     ]
    }
   ],
   "source": [
    "split1, split2 = round(0.7*len(data)), round(0.8*len(data))\n",
    "train, valid, test = data.iloc[:split1], data.iloc[split1:split2], data.iloc[split2:]\n",
    "train_x, valid_x, test_x = train[x_columns], valid[x_columns], test[x_columns]\n",
    "train_y_all, valid_y_all, test_y_all = np.array(train[y_columns]), np.array(valid[y_columns]), np.array(test[y_columns])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_x = scaler.fit_transform(train_x) \n",
    "valid_x = scaler.transform(valid_x)\n",
    "test_x  = scaler.transform(test_x)\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "valid_x = valid_x.reshape((valid_x.shape[0], 1, valid_x.shape[1]))\n",
    "test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))\n",
    "print(train_x.shape, valid.shape, test_x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "\n",
    "### Model design\n",
    "We have 375 different targets (stock return time series) we want to predict separately, by using the same predictors (the whole cross-section of the aforesaid variables for each point in time). We would like to use the same model architecture for each stock, but the trained models will be estimated separately (375 different estimations). As previously mentioned, the objective is to predict the one-day-ahead return for each of the 375 stocks. The recurrent neural network consists in a two-layer LSTM with 50 and 100 units, respectively. Each stock's model is trained separately, and early stopping is adopted to avoid overfitting. More specifically, $R^2$ metric is evaluated for the decision of the optimal stopping point. According to Gu et al. (2020), \"predicting future excess stock returns with historical averages typically underperforms a naive forecast of zero by a large margin\". Thus, the denominator of our $R^2$ metric is not \"demeaned\". The various hyperparameters are empirically chosen after some manual trial end error approach on a sub-sample of stocks. Even though a Grid / Random Search would be more effective, it was out of the scope of the exercise.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define modified r-squared\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  backend.sum(backend.square( y_true-y_pred ))\n",
    "    SS_tot = backend.sum(backend.square( y_true))           \n",
    "    return ( 1 - SS_res/SS_tot)\n",
    "\n",
    "\n",
    "# define model\n",
    "def lstm_model(train_x, train_y, valid_x, valid_y):\n",
    "    \n",
    "    # define early stopping\n",
    "    earlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_r2', patience=50, mode=\"max\", \n",
    "                                                restore_best_weights=True)\n",
    "    # design network\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(LSTM(50, activation=\"relu\", input_shape=(None, train_x.shape[2]),\n",
    "                    return_sequences=True, dropout=0.4))\n",
    "    model.add(LSTM(100, activation=\"relu\", return_sequences=False,))                     \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # model compile & fit\n",
    "    model.compile(loss='mse',  optimizer=RMSprop(lr=0.0005), metrics=[r2])\n",
    "    history = model.fit(train_x, train_y, epochs=1000, batch_size=256, validation_data=(valid_x, valid_y), \n",
    "                        verbose=2, callbacks=[earlystopper], shuffle=False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "The following cell estimates the model parameters for each stock.  It takes long to run, thus code is hashed by default. Use  predictions coming from already-trained models instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# estimate model for each stock\n",
    "# set seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "# initialize empty dataframe for predictions\n",
    "test_y_pred = pd.DataFrame()\n",
    "\n",
    "# estimate model for each stock\n",
    "for train_y, valid_y, stock_name in tqdm(zip(train_y_all.transpose(), valid_y_all.transpose(), y_columns),\n",
    "                                         total=len(y_columns)):\n",
    "    \n",
    "    model = lstm_model(train_x, train_y, valid_x, valid_y)\n",
    "    \n",
    "    # make predictions on testset and store them in dataframe\n",
    "    y_pred = model.predict(test_x)\n",
    "    y_pred = pd.DataFrame(y_pred, columns = [stock_name], index = test[x_columns].index)\n",
    "    test_y_pred = pd.concat([test_y_pred, y_pred], axis=1)\n",
    "    \n",
    "\n",
    "pickle.dump(test_y_pred, open(\"test_y_pred.pkl\", \"wb\"))\n",
    "pickle.dump(dict_r2, open(\"dict_r2.pkl\", \"wb\"))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_r</th>\n",
       "      <th>AAPL_r</th>\n",
       "      <th>ABC_r</th>\n",
       "      <th>ABMD_r</th>\n",
       "      <th>ABT_r</th>\n",
       "      <th>ADBE_r</th>\n",
       "      <th>ADI_r</th>\n",
       "      <th>ADM_r</th>\n",
       "      <th>ADP_r</th>\n",
       "      <th>ADSK_r</th>\n",
       "      <th>...</th>\n",
       "      <th>WST_r</th>\n",
       "      <th>WY_r</th>\n",
       "      <th>XEL_r</th>\n",
       "      <th>XLNX_r</th>\n",
       "      <th>XOM_r</th>\n",
       "      <th>XRAY_r</th>\n",
       "      <th>XRX_r</th>\n",
       "      <th>YUM_r</th>\n",
       "      <th>ZBRA_r</th>\n",
       "      <th>ZION_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-13</th>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>-0.000414</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.001348</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>-0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-14</th>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>-0.000353</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>-0.000296</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>-0.001847</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.001077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-15</th>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A_r    AAPL_r     ABC_r    ABMD_r     ABT_r    ADBE_r  \\\n",
       "Date                                                                     \n",
       "2016-07-13  0.001119  0.002010 -0.000103  0.000374 -0.000366  0.000094   \n",
       "2016-07-14  0.001014  0.002079  0.000881  0.003736 -0.000353  0.000452   \n",
       "2016-07-15  0.001010  0.002068  0.000473  0.002761  0.000255  0.000319   \n",
       "\n",
       "               ADI_r     ADM_r     ADP_r    ADSK_r  ...     WST_r      WY_r  \\\n",
       "Date                                                ...                       \n",
       "2016-07-13  0.000136  0.000213 -0.000459 -0.000242  ...  0.000673 -0.000414   \n",
       "2016-07-14  0.000289 -0.001765 -0.000296 -0.000531  ...  0.002122  0.000283   \n",
       "2016-07-15  0.000201 -0.000716 -0.000132 -0.000314  ...  0.001077 -0.000533   \n",
       "\n",
       "               XEL_r    XLNX_r     XOM_r    XRAY_r     XRX_r     YUM_r  \\\n",
       "Date                                                                     \n",
       "2016-07-13  0.000431 -0.001348 -0.001022  0.000117  0.000143  0.000928   \n",
       "2016-07-14  0.000907 -0.001847 -0.000206  0.000348 -0.000085  0.001122   \n",
       "2016-07-15  0.000510 -0.001710 -0.001133  0.000176 -0.000523  0.000947   \n",
       "\n",
       "              ZBRA_r    ZION_r  \n",
       "Date                            \n",
       "2016-07-13  0.001959 -0.000191  \n",
       "2016-07-14  0.001229  0.001077  \n",
       "2016-07-15  0.000798  0.000548  \n",
       "\n",
       "[3 rows x 375 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_r</th>\n",
       "      <th>AAPL_r</th>\n",
       "      <th>ABC_r</th>\n",
       "      <th>ABMD_r</th>\n",
       "      <th>ABT_r</th>\n",
       "      <th>ADBE_r</th>\n",
       "      <th>ADI_r</th>\n",
       "      <th>ADM_r</th>\n",
       "      <th>ADP_r</th>\n",
       "      <th>ADSK_r</th>\n",
       "      <th>...</th>\n",
       "      <th>WST_r</th>\n",
       "      <th>WY_r</th>\n",
       "      <th>XEL_r</th>\n",
       "      <th>XLNX_r</th>\n",
       "      <th>XOM_r</th>\n",
       "      <th>XRAY_r</th>\n",
       "      <th>XRX_r</th>\n",
       "      <th>YUM_r</th>\n",
       "      <th>ZBRA_r</th>\n",
       "      <th>ZION_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-13</th>\n",
       "      <td>-0.002582</td>\n",
       "      <td>-0.005662</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>-0.005702</td>\n",
       "      <td>-0.002053</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>-0.004399</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>-0.008928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008307</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.010292</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>-0.002379</td>\n",
       "      <td>-0.006224</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>-0.010113</td>\n",
       "      <td>-0.002345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-14</th>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.019627</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>-0.007766</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.018228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-15</th>\n",
       "      <td>-0.002782</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>-0.005449</td>\n",
       "      <td>-0.004266</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006407</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>-0.004754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008876</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>-0.000384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A_r    AAPL_r     ABC_r    ABMD_r     ABT_r    ADBE_r  \\\n",
       "Date                                                                     \n",
       "2016-07-13 -0.002582 -0.005662  0.008870 -0.002125 -0.005702 -0.002053   \n",
       "2016-07-14  0.008368  0.019627  0.011938  0.002295  0.007359  0.003692   \n",
       "2016-07-15 -0.002782 -0.000101 -0.004665 -0.005449 -0.004266  0.001330   \n",
       "\n",
       "               ADI_r     ADM_r     ADP_r    ADSK_r  ...     WST_r      WY_r  \\\n",
       "Date                                                ...                       \n",
       "2016-07-13  0.008944 -0.004399  0.003475 -0.008928  ... -0.008307  0.003760   \n",
       "2016-07-14  0.008366  0.008778  0.000735  0.022430  ...  0.004737  0.002187   \n",
       "2016-07-15  0.002163  0.010752 -0.001577 -0.003100  ... -0.006407 -0.000312   \n",
       "\n",
       "               XEL_r    XLNX_r     XOM_r    XRAY_r     XRX_r     YUM_r  \\\n",
       "Date                                                                     \n",
       "2016-07-13  0.010292  0.002944 -0.000737 -0.002379 -0.006224  0.001749   \n",
       "2016-07-14 -0.007766  0.004609  0.000737  0.004436  0.004154  0.029081   \n",
       "2016-07-15  0.003205  0.001254  0.001789 -0.004754  0.000000 -0.008876   \n",
       "\n",
       "              ZBRA_r    ZION_r  \n",
       "Date                            \n",
       "2016-07-13 -0.010113 -0.002345  \n",
       "2016-07-14  0.003855  0.018228  \n",
       "2016-07-15  0.012278 -0.000384  \n",
       "\n",
       "[3 rows x 375 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load predicted returns for each stock from .pkl file\n",
    "test_y_pred = pickle.load(open(\"test_y_pred.pkl\", \"rb\" ))\n",
    "test_y_all = test[y_columns]\n",
    "display(test_y_pred.head(3))\n",
    "display(test_y_all.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of out-of-sample performance\n",
    "After we collected the matrix of predictions, we apply a simple long/short equally-weighted trading strategy. Specifically, we  buy (sell) top-(bottom-)5% stocks ranked by predicted return and adjust portfolio daily. We use Sharpe Ratio and maximum drawdown as performance metrics for both the strategy based on neural network predictions and a passive strategy holding S&P500 index over the period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "# define signal to buy (sell) top (bottom) 5% stocks ranked by predicted return\n",
    "def top_bottom_signal(series, percentile=0.05):\n",
    "    n_avail_stocks = max(series.dropna())\n",
    "    right = int(n_avail_stocks*(1-percentile))\n",
    "    left = int(n_avail_stocks*percentile)\n",
    "    return np.where(series<=left, -1, np.where(series>=right, 1, 0))\n",
    "\n",
    "def maximumDrawdown(cum_rets):\n",
    "    mdd = 0\n",
    "    cum_rets = np.array(cum_rets)\n",
    "    peak = cum_rets[0]\n",
    "    for ret in cum_rets:\n",
    "        if ret > peak: peak = ret\n",
    "        dd = (peak - ret) / peak\n",
    "        if dd > mdd: mdd = dd\n",
    "    return float(mdd)\n",
    "\n",
    "def sharpeRatio(returns, rf_rates):\n",
    "    return float(((np.mean(returns)-np.mean(np.array(tbill)))/np.std(returns)) * 252**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"450\" style=\"\" viewBox=\"0 0 700 450\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"450\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-7d28a8\"><g class=\"clips\"><clipPath id=\"clip7d28a8xyplot\" class=\"plotclip\"><rect width=\"503\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clip7d28a8x\"><rect x=\"80\" y=\"0\" width=\"503\" height=\"450\"/></clipPath><clipPath class=\"axesclip\" id=\"clip7d28a8y\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clip7d28a8xy\"><rect x=\"80\" y=\"100\" width=\"503\" height=\"270\"/></clipPath></g><g class=\"gradients\"/></defs><g class=\"bglayer\"/><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"gridlayer\"><g class=\"x\"/><g class=\"y\"/></g><g class=\"zerolinelayer\"/><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(80, 100)\" clip-path=\"url('#clip7d28a8xyplot')\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace49902f\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,242.97L0.71,243.53L1.78,243.75L2.49,242.46L2.84,239.6L3.2,240.44L4.27,240.86L5.33,241.56L5.69,240.18L7.82,238.47L8.18,239.06L9.24,239.5L9.6,238.48L9.95,238.35L10.31,239.65L12.44,242.96L12.8,245.55L13.15,245.56L14.22,244.78L15.29,244.41L15.64,245.51L17.06,245.78L17.42,244.86L18.13,245.49L19.55,246.13L19.91,246.1L20.26,248.62L21.68,246.03L22.04,245.02L22.4,243.89L22.75,244.36L23.11,244.75L24.53,244.09L24.88,244.71L25.59,242.95L26.66,242.87L27.02,242.07L27.37,243.68L28.08,243.84L29.15,244.01L29.86,247.44L30.22,247.05L30.57,247.14L31.99,244.46L32.35,242.53L32.7,241.56L33.06,241.78L34.13,240.82L34.48,240.18L34.84,241.42L35.19,242.57L35.55,242.12L36.61,241.98L37.68,247.56L38.04,245.58L39.1,244.49L39.46,246.63L40.52,243.43L41.59,241.66L41.95,240.56L42.3,243.17L44.08,248.98L44.43,248.2L45.15,245.94L45.5,246.39L46.57,246.34L47.28,248.11L47.99,247.09L49.41,247.53L49.77,248.25L50.12,249.55L50.48,248.67L51.54,249.29L51.9,247.95L52.26,250.51L52.61,250.28L52.97,251.15L55.1,246.85L55.45,245.93L56.52,245.72L56.88,246.88L57.23,247.2L57.59,250L57.94,249.72L59.36,250.46L60.43,248.66L61.85,249.26L62.92,246.58L63.99,243.05L64.7,244.9L65.05,242.35L65.41,242.61L66.83,241.33L67.54,241.44L67.9,240.61L68.96,240.1L69.32,241.54L70.03,243.56L70.38,242.57L71.45,242.99L71.81,239.52L72.52,244.1L72.87,243.39L73.94,242.81L75.01,241.73L75.36,241.93L76.78,241.7L77.14,240.65L77.85,240.53L79.27,239.97L79.63,240.17L79.98,239.38L80.34,238.21L81.4,238.52L81.76,237.87L82.12,240.62L83.89,242.11L84.25,242.24L84.96,242.44L85.31,243.19L87.09,242.72L87.45,242.25L88.87,239.66L89.22,240.36L89.58,241.5L89.94,240.68L90.29,240.43L91.71,242.51L92.07,240.77L92.78,239.95L93.85,238.96L94.2,240.16L94.56,239.37L94.91,239.13L95.27,239.3L96.33,238.96L97.4,236.91L98.82,236.93L99.89,235.28L100.24,236.16L101.31,236.4L101.67,235.09L102.73,237.91L103.8,237.35L104.87,231.41L105.22,232.35L106.29,232.42L106.64,233.69L107.35,233.47L107.71,233.98L108.78,233.29L109.13,235.17L110.2,230.49L111.26,229.84L112.33,224.41L112.69,224.53L114.11,224.57L114.82,224.22L115.17,223.56L116.24,223.14L116.6,224.68L116.95,223.72L117.31,226.57L117.66,227.25L118.73,226.16L119.08,226.47L119.44,225.27L119.8,223.23L120.15,223.43L121.22,225.24L121.57,226.12L121.93,225.96L122.28,225.46L122.64,226.44L123.71,225.64L124.06,225.73L124.42,226.96L126.91,226.06L127.26,226.5L128.68,229.97L129.04,229.58L129.39,230.03L129.75,228.79L130.1,227.07L131.17,227.64L133.66,222.12L134.01,222.74L135.08,221.27L136.15,221.69L136.5,223.05L136.86,221.1L137.57,221.43L138.64,220.86L138.99,223.25L139.35,222.62L139.7,221.12L141.48,222.42L141.84,220.35L142.19,219.35L142.55,220.79L143.61,218.98L143.97,219.9L144.68,223.06L145.03,222.99L146.1,222.34L146.46,223.03L146.81,222.35L147.17,219.48L147.52,220.14L148.94,220.24L149.3,220.59L149.66,219.64L150.01,217.22L151.08,216.35L151.79,218.9L152.14,218.15L152.5,220.72L153.57,219.28L153.92,220.65L154.99,222.89L156.05,223.03L156.41,222.67L156.77,223.8L157.48,222.25L158.54,221.02L159.96,220.26L161.03,221.62L162.1,220.73L162.45,220.87L163.52,220.15L163.87,221.64L164.59,221.79L164.94,223.36L166.01,222.62L166.36,223.92L167.43,225.56L168.5,226.48L168.85,225.97L169.21,228.44L169.92,225.21L170.98,227.23L171.7,222.33L172.05,223.85L172.41,224.34L173.47,222.91L173.83,223.28L174.18,223.89L174.54,223.54L174.89,224.11L175.96,224.86L176.32,224.98L176.67,226.14L177.38,225.17L178.45,225.26L178.8,225.73L179.16,228.67L179.87,227.57L180.94,228.73L181.29,230.19L181.65,229.44L182,229.55L183.43,228.77L183.78,227.65L184.85,222.57L185.91,222.42L186.27,221.69L186.63,223.68L187.34,223.18L188.76,223.17L191.25,223.63L191.6,224.32L191.96,225.12L192.31,223.83L194.09,221.26L194.45,222.09L194.8,222.86L196.22,223.92L197.29,219.83L198.36,219.44L198.71,222.76L199.07,222.57L199.42,221.92L202.27,223.1L203.33,222.33L204.75,220.34L205.82,220.65L206.53,221.18L206.89,220.08L209.02,222.72L209.38,224.51L210.8,226.14L211.15,227.55L211.86,225.58L212.22,227.17L213.64,227.67L214,226.53L214.71,223.86L215.77,224.47L216.13,224.3L216.49,223.09L216.84,222.67L217.2,223.89L218.62,225.36L218.97,227.84L219.33,227.93L219.68,226.52L220.75,225.76L221.11,224.52L221.46,222.38L221.82,222.8L223.24,224.69L223.95,224.68L224.31,223.82L224.66,221.99L225.73,221.78L226.79,222.72L227.15,221.17L228.22,221.74L228.57,219.28L228.93,218.47L229.28,219.49L229.64,220.45L231.06,220.1L231.42,221.21L231.77,224.05L232.13,223.9L233.19,224.17L233.55,223.51L233.9,225.19L234.26,225L234.61,223.78L236.04,223.12L236.39,220.29L237.1,220.73L238.17,220.28L238.53,220.65L238.88,223.11L239.24,223.75L239.59,222.96L240.66,221.53L242.08,215.81L243.5,215.26L243.86,215.46L244.21,214.35L244.57,217.1L245.63,217.33L246.7,218.69L247.06,218.57L248.12,216.97L248.48,213.79L249.54,208.08L250.61,207.99L251.32,207.08L251.68,205.03L252.03,205.4L253.1,205.3L253.46,205.26L253.81,207.55L254.52,209.51L255.59,208.29L256.65,206.38L257.01,206.08L258.43,208.33L258.79,205.77L259.14,204.68L259.5,205.39L260.56,205.28L261.63,205.41L261.99,204.62L263.05,204.9L263.41,204.12L263.76,202.4L264.12,206.49L264.47,207.13L265.54,205.81L266.96,206.15L268.03,208.15L268.39,208.17L268.74,206.91L269.45,208.63L270.52,208.91L271.58,208.4L271.94,209.52L273.01,209.6L273.36,211.12L274.43,208.02L275.49,207.96L276.21,206.47L276.56,207.46L276.92,206.44L278.34,205.81L278.69,205.75L279.05,204.03L280.47,204.38L280.83,203.47L281.89,205.74L282.96,206.11L284.38,210.59L285.45,210.22L286.51,211.89L286.87,210.12L287.94,210.02L288.29,212L289,214.76L289.36,213.47L290.42,212.8L290.78,214.09L291.85,211.49L292.91,210.86L293.62,213.03L293.98,210.54L294.33,207.28L295.4,208.4L296.82,199.71L297.89,199.78L298.25,197.97L298.6,198.78L298.96,200.23L299.31,200.83L300.38,200.3L300.73,200.77L301.09,198.87L301.8,196.38L302.87,195.48L304.29,191.53L305.35,192.36L305.71,189.35L306.07,190.02L306.78,189.13L307.84,187.19L308.2,188.75L309.27,187.05L310.33,187.83L310.69,188.96L311.4,187.16L311.75,190.04L312.82,189.05L313.89,185.68L314.24,183.79L315.31,184.59L315.66,182.8L316.02,181.55L316.37,183.67L316.73,185.31L317.8,183.39L319.22,180.06L320.28,180.54L321,183.1L321.35,181.62L321.71,181.77L323.48,176.88L323.84,175.58L325.26,175.52L325.62,174.52L325.97,173.68L326.33,174.23L326.68,174.71L328.46,176.58L328.82,174.97L330.24,174.26L330.59,178.24L331.3,178.41L331.66,177.05L333.08,176.38L333.44,179.37L334.15,175.26L335.21,175.08L335.57,175.87L335.93,174.57L336.28,173.63L336.64,174.1L338.06,175.2L338.77,171.69L339.13,172.05L340.19,171.96L340.55,172.19L340.9,169.31L341.61,168.4L342.68,169.02L343.39,167.11L343.75,169.17L344.1,167.83L345.17,169.36L345.52,169.69L345.88,168.83L346.59,167.12L347.66,168.85L348.01,168.76L348.37,169.52L349.08,173.94L350.14,174.1L351.21,175.71L351.57,174.88L354.06,181.05L355.12,181.72L356.19,183.66L356.54,186.12L357.61,184.9L357.97,186.82L358.32,186.64L358.68,188.13L360.81,188.09L361.16,188.59L361.52,186.95L362.59,186.79L363.65,182.26L364.01,182.46L365.07,182.34L365.43,179.6L365.79,181.9L366.14,180.8L366.5,180L368.27,178.82L368.63,179.28L368.99,178.75L370.05,179.17L370.41,178.43L370.76,178.65L371.12,175.87L371.47,175.57L372.9,176.01L373.25,179.06L373.61,176.61L373.96,173.88L375.03,173.3L375.38,174.93L375.74,174.13L376.09,175.27L376.45,173.74L377.52,174.08L377.87,174.9L378.23,173.02L378.94,173.05L380,172.31L381.07,175.67L381.43,173.92L382.49,173.59L382.85,172.27L383.2,176.02L383.56,175.31L383.92,172.42L384.98,173.89L385.34,170.87L385.69,170.7L386.4,171.33L388.18,175.58L388.54,174.47L388.89,174.41L389.96,172.47L390.31,172.32L390.67,168.92L391.02,166.92L391.38,169.06L392.45,171.12L392.8,169.58L393.16,170.11L393.51,170.98L393.87,166.96L394.93,166.87L395.65,165.5L396,167.07L396.36,164.73L397.42,165.95L398.85,169.85L399.91,169.06L400.98,167.23L401.33,167.44L402.4,167.18L403.82,165.11L404.89,165.57L406.31,161.2L407.73,161.1L408.09,161.58L408.44,160.96L408.8,159.39L409.87,161.24L410.22,160.08L410.93,157.93L411.29,159.48L412.35,161.33L412.71,160.07L413.42,158.68L413.78,159.71L415.2,161.43L415.55,160.12L415.91,160.38L416.26,159.68L417.33,158.7L417.69,159.56L418.04,159.62L418.4,160.78L418.75,158.29L419.82,158.36L420.88,157.01L421.24,158.54L422.31,159.14L422.66,160.71L423.02,160.98L423.37,160.04L423.73,157.38L424.8,159L425.86,160.89L426.22,160.76L427.28,159.59L427.64,157.03L427.99,154.41L428.35,154.62L428.71,154.8L429.77,157.39L430.13,155.16L431.19,151.96L432.26,150.86L432.62,151.72L432.97,150.8L433.33,150.7L433.68,150.68L434.75,149.66L435.1,147.64L435.81,147.93L436.17,146.71L437.24,146.98L437.59,144.06L438.66,145.13L439.73,144.26L440.08,141.97L440.44,142.56L440.79,142.67L441.15,143.95L442.21,143.78L442.57,144.63L442.92,143.95L443.28,148.52L443.64,147.88L444.7,149.9L446.12,154.71L447.19,155.08L447.55,155.56L448.26,154.85L448.61,153.67L449.68,154.17L450.74,153.86L451.1,155.86L452.52,153.83L452.88,151.5L453.59,148.98L454.66,149.62L458.21,140.77L458.57,141.92L460.34,138.88L460.7,140.21L461.05,140.06L462.12,141.01L462.83,140.03L463.19,140.65L463.54,142.71L464.61,142.52L465.32,138.67L465.67,140.67L466.03,139.92L467.45,139.82L467.81,142.76L468.52,140.68L469.59,139.78L470.65,136.79L471.01,137.09L472.07,136.82L472.43,137.54L473.5,145L474.56,162.69L474.92,154.2L475.27,159.71L475.63,168.08L475.98,159.57L477.05,166.25L478.47,185.1L479.54,185.89L480.6,162.39L480.96,165.76L482.03,164.21L482.38,166.97L482.74,160.9L483.45,169.76L484.52,166.12L485.23,168.31L485.58,174.28L487,173.63L487.36,168.27L488.07,152.3L488.43,155.7L489.49,157.56L489.85,157.82L490.2,157.07L490.91,152.97L491.98,156.32L492.34,156.56L492.69,157.94L493.05,159.72L493.4,156.16L494.82,154.25L495.18,155.59L495.89,153.22L496.96,152.37L497.31,152.43L497.67,154.41L499.45,142.4L499.8,140.38L500.16,139.11L500.51,140.29L500.87,140.6L502.64,141.9L503,138.23\" style=\"vector-effect: non-scaling-stroke; fill: none; stroke: rgb(0, 128, 240); stroke-opacity: 1; stroke-width: 1.3px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter trace28a7cf\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,242.48L0.36,240.21L0.71,240.62L1.78,239.58L2.13,240.21L2.49,238.36L2.84,239.94L3.2,237.96L4.98,239.66L5.33,238.96L5.69,238.25L6.75,238.81L7.11,241.59L7.47,240.23L7.82,240.14L8.18,236.42L9.24,236.82L9.6,236.65L9.95,237.9L10.31,235.84L10.66,236.19L11.73,234.97L12.09,237.38L12.44,236.57L12.8,235.61L13.15,236.24L14.22,236.49L14.57,235.63L14.93,237.94L15.64,239.22L16.71,236.95L17.77,238.86L18.13,237.04L19.91,235.8L20.26,236.78L20.62,247.64L21.68,241.42L22.4,248.14L22.75,243.85L23.11,245.48L24.17,245.49L24.53,245.36L24.88,240.7L25.24,237.9L25.59,240.41L26.66,244.15L27.37,239.1L27.73,243.17L28.08,239.75L29.15,241.17L29.5,243.32L29.86,241.48L30.22,241.27L30.57,242.68L31.64,240.69L32.7,246.96L33.06,246.88L34.13,248.18L34.48,245.56L34.84,244.62L35.19,245.21L35.55,245.25L36.61,243.22L36.97,244.86L38.04,248.22L39.1,248.27L40.52,256.5L41.59,247.32L42.66,240.15L43.01,240.76L44.08,240.81L45.15,236.23L45.5,237.28L47.99,231L49.06,233.33L49.41,232.75L49.77,233.92L50.12,235.47L50.48,235.29L51.54,232.75L51.9,231.24L52.26,225.45L52.97,221.82L54.03,222.34L54.39,219.39L54.74,223.1L55.1,221.35L55.45,222.14L56.52,221.25L56.88,219.61L57.23,220.72L57.59,221.57L59.36,219.99L59.72,223.8L60.08,223.93L60.43,226.02L62.92,218.41L63.99,220.03L64.34,220.03L64.7,218.75L65.05,219.73L65.41,218.89L66.83,220.24L67.19,219.44L67.54,221.08L67.9,219.56L68.96,220.79L69.67,214.17L70.03,214.51L70.38,214.91L72.16,217.95L72.52,217.69L72.87,214.38L73.94,215.36L74.65,214.93L75.01,212.3L77.14,204.04L77.49,204.44L79.27,200.82L79.63,201.33L79.98,201.13L81.4,199.95L81.76,201.17L82.12,194.75L82.47,197.56L82.83,197.32L84.25,200.28L84.6,201.36L84.96,200.98L85.31,199.44L86.38,199.26L86.74,200.87L87.09,196.92L87.45,197.7L87.8,198.33L88.87,199.28L89.22,205.21L89.58,204.33L89.94,204.83L90.29,205.22L91.36,205.7L91.71,202.32L92.42,200.42L92.78,201.49L94.2,202L94.56,203.45L94.91,202.54L95.27,202.93L96.33,202.61L97.05,205.06L97.4,208.26L98.82,204.27L99.18,205.63L99.53,206.44L99.89,202.92L100.24,204.35L101.31,199.28L102.38,196.37L102.73,197.28L104.87,196.22L105.22,194.27L107,194.2L107.35,195.24L107.71,195.95L108.78,193.67L109.13,194L109.49,202.81L111.62,194.56L111.98,193.36L112.69,191.08L114.11,191.67L114.46,191.89L114.82,188.25L115.17,186.45L116.24,187.05L116.6,188.4L116.95,187.64L117.31,187.51L118.73,188.39L119.08,186.2L120.15,187.64L121.22,183.6L122.28,187.4L122.64,186.64L123.71,186.49L124.06,190.44L124.42,186.2L124.77,190.41L125.13,189.67L126.91,187.85L127.26,192.43L127.62,189.35L128.68,188.9L129.04,189.28L129.39,185.75L130.1,182.56L131.17,182.58L131.53,182.29L131.88,179.65L133.66,180.44L134.01,179L134.73,179.34L135.08,180L136.15,180.36L136.5,179.16L136.86,178.91L137.21,179.99L138.64,178.25L138.99,179.45L139.35,179.63L139.7,186.84L140.06,186.21L141.12,181.34L141.48,181.58L141.84,180.88L142.55,189.45L143.61,188.89L143.97,184.09L144.32,185.78L144.68,186.8L145.03,185.98L146.1,185.75L146.46,185.33L146.81,183.08L147.52,179.3L148.94,183.05L149.3,181.52L149.66,181.61L150.01,182.34L151.79,174.99L152.14,175.54L152.5,174.62L154.28,173.02L154.63,174.55L154.99,174.23L156.05,175.34L156.41,175.3L156.77,173.27L158.54,168.87L158.9,167.78L159.25,167.14L159.61,164.29L161.03,165.76L161.39,164.58L161.74,163.66L162.1,164.52L162.45,164.07L164.59,162.29L164.94,159.68L166.01,161.73L166.36,160.9L166.72,163.3L167.07,162.65L167.43,158.54L168.5,160.18L168.85,159.7L169.21,158.88L169.56,158.78L169.92,157.19L171.7,155.88L172.05,157.84L172.41,158.3L173.47,157.79L174.18,161.84L174.54,157.66L174.89,159.02L175.96,158.36L176.32,155L176.67,155.39L177.38,154.32L178.45,154.52L178.8,149.43L179.16,149.62L179.52,145.34L179.87,146.42L180.94,146.97L181.65,149.01L182,147.47L182.36,144.58L183.43,142.88L183.78,142.06L184.14,142.31L184.49,144.48L184.85,139.75L185.91,136.89L186.63,139.07L186.98,138.01L188.76,138.83L189.11,138.4L189.47,137.42L189.82,140.21L191.6,132.36L191.96,130.18L192.31,126.37L193.38,125.46L193.73,124.74L194.09,125.36L194.45,121.51L194.8,117.79L196.22,119.76L197.29,113.02L198.36,108.51L199.42,107.26L199.78,100.59L200.84,104.46L201.2,110.7L201.91,110.79L202.27,122.87L203.33,145.94L203.69,136.81L204.04,139.5L204.4,159.96L205.82,145.12L206.18,143.74L207.24,130.03L208.67,133.22L209.02,136.2L209.38,135.67L209.73,127.11L210.8,120.72L211.15,127.79L211.86,141.14L212.22,138.44L213.29,132.56L214.35,128.98L214.71,119.59L215.77,120.3L216.13,123.83L216.84,127.42L217.2,126.49L218.97,134.52L219.33,148.28L219.68,159.42L220.75,145.63L221.46,156.35L221.82,149.27L223.24,161.13L223.6,154.7L224.31,145.13L224.66,156.86L225.73,155.13L226.08,146.52L226.44,149.45L226.79,145.14L227.15,146.66L228.22,142.4L228.93,136.32L229.28,139.41L229.64,143.99L230.7,143.96L231.06,151.1L231.42,150.14L231.77,144.7L232.13,144.12L233.19,148.47L233.55,147.14L233.9,150.95L234.26,152.13L234.61,145.48L236.04,143.8L236.39,138.69L237.1,132.77L238.17,132.29L238.53,136.01L238.88,133.83L239.24,134.29L239.59,135.72L240.66,131.75L241.01,133.46L241.37,131.7L241.72,132.8L243.5,140.36L243.86,133.63L244.21,137.36L244.57,131.57L245.99,128.76L246.35,124.11L246.7,124.5L247.06,122.78L248.48,121.23L248.83,123.46L249.19,122.1L249.54,122.67L250.61,123.84L251.68,128.62L252.03,127.6L253.81,138.64L254.17,135.34L255.59,133.28L255.94,135.96L258.43,120.03L258.79,123.98L259.5,118.59L260.56,119.16L261.28,115.75L261.63,117.97L261.99,118.49L263.05,117.47L263.76,109.75L264.12,111.46L264.47,115.17L265.54,118.39L265.9,115.69L266.25,116.27L266.61,113.53L266.96,110.93L268.03,108.94L268.39,107.34L268.74,107.49L269.1,108.31L269.45,112.35L270.52,114.61L270.87,111.04L271.23,115.34L271.94,109.06L273.01,107.69L273.36,106.52L273.72,106.75L274.07,107.71L275.49,99.85L275.85,99.7L276.21,96.43L276.56,99L276.92,98.92L278.34,99.87L278.69,101.48L279.4,104.84L280.47,103.76L281.89,98.25L282.96,101.47L284.03,93.18L284.38,93.4L285.45,95.44L286.16,98.1L286.51,96.51L286.87,96.52L287.94,94.42L288.65,94.23L289,98.99L289.36,102.18L290.42,102.41L290.78,103.22L291.14,122.3L291.49,133.77L291.85,126.15L292.91,129.39L293.27,117.8L293.62,117.95L293.98,126.01L294.33,126.21L295.4,128.57L295.76,131.58L296.11,148.59L296.47,138.9L296.82,148.25L297.89,151.71L298.96,132.23L299.31,135.67L300.38,132.66L300.73,129.28L301.09,117.84L301.44,119.24L301.8,124.37L303.58,140.2L303.93,134.57L304.29,133.37L305.35,142.45L305.71,152.19L306.07,150.6L306.78,154.04L308.2,144.31L308.55,132.27L308.91,133.46L309.27,129.06L310.33,123.12L310.69,141.25L311.4,142.07L311.75,154.62L313.18,153.89L313.53,151.08L313.89,151.19L314.24,161.26L316.02,179.78L316.37,187.64L317.8,210.86L318.51,188.43L318.86,184.29L319.22,184.9L320.28,180.76L321,180.13L321.35,192.52L321.71,176.26L322.77,172.78L323.84,163.58L324.2,163.65L325.26,166.35L326.68,149.11L328.11,156.6L328.82,154.75L329.17,150.36L330.59,155.24L330.95,147.23L331.66,142.24L332.73,138.65L333.08,136.14L333.44,137.34L333.79,142.38L335.21,141.65L335.57,134.82L335.93,133.2L336.28,134.63L336.64,128.79L338.41,127.01L338.77,128.94L339.13,125.46L340.19,124.78L341.26,127.07L341.61,123.31L343.04,126.07L343.39,129.66L344.1,135.25L345.17,127.41L346.59,119.73L347.66,117.68L348.01,117.75L348.37,119.4L348.72,113.41L349.08,124.15L350.14,124.61L350.5,120.68L350.86,123.25L351.21,121.28L351.57,117.57L354.06,106.16L355.12,105.56L355.48,109.02L355.83,107.06L356.19,107.04L356.54,103.3L357.61,103.66L357.97,103.37L358.32,104.67L358.68,103.77L360.1,103.2L360.45,98.17L360.81,99.44L361.16,99.65L361.52,96.96L362.59,96.34L362.94,95.79L363.3,100.15L363.65,101.37L364.01,95.88L365.07,98.47L365.43,108.05L366.14,110.67L366.5,108.58L367.56,122.4L367.92,117.99L368.27,114.75L368.63,109.8L368.99,113.1L370.05,116.9L370.41,112.19L370.76,113.78L371.12,120.49L371.47,119.74L372.9,124.41L373.96,134.34L375.03,135.84L376.45,110.74L377.52,108.12L377.87,108.32L378.23,109.47L378.58,107.16L378.94,108.08L380,107.55L381.07,94.96L381.43,95.69L382.49,96.69L383.2,102.91L383.56,100.73L384.98,93.03L385.34,91.33L385.69,86.87L386.4,87.93L387.47,90.78L387.83,90.05L388.18,87.43L388.89,83.38L389.96,83.27L391.38,90.69L392.45,89.04L393.87,81.08L394.93,82.04L395.29,83.57L395.65,90.04L397.42,116.92L397.78,109.71L398.13,109.28L398.49,98.78L399.91,109.68L400.27,101.2L400.62,118.24L400.98,116.87L401.33,108.89L402.4,102.09L402.76,106.63L403.11,101.97L403.47,102.26L403.82,117.3L405.6,109.36L405.95,102.24L406.31,101.87L407.73,105.83L408.8,91.75L409.87,91.8L410.22,91.61L410.58,87.42L410.93,85.73L411.29,86.16L412.35,88L413.42,86.28L413.78,89.16L414.84,89.22L415.2,94.17L415.55,90.6L415.91,92.02L416.26,95.13L417.33,92.21L417.69,99.39L418.04,109.77L418.4,105.29L418.75,97.26L419.82,99.85L420.17,108.86L421.24,93.84L422.31,94.65L423.37,88.46L423.73,90.76L424.8,86.77L425.15,88.87L427.28,80.4L427.64,80.9L429.77,72.85L430.13,73.56L430.48,73.14L430.84,71.5L431.19,69.96L432.26,71.15L433.33,69.27L433.68,64.63L435.1,64.69L435.46,66.98L435.81,67.94L436.17,66.63L437.95,58.18L438.66,60.66L440.08,70.03L440.44,66.22L440.79,65.31L441.15,59.77L442.57,62.39L442.92,60.61L443.64,55.33L444.7,50.92L445.41,50.98L445.77,48.21L446.12,45.12L447.19,44.58L447.55,44.7L448.26,41.48L448.61,41.46L449.68,45.13L450.74,38.01L451.1,42.52L452.17,40.29L452.52,42.07L453.23,34.77L453.59,36.6L454.66,32.16L455.01,33.14L455.37,31.94L455.72,26.59L456.08,24.09L457.5,25.82L458.21,24.89L458.57,30.79L459.63,40.99L459.99,34.66L460.34,35.21L460.7,33.21L461.05,44.66L462.12,40.11L463.19,21.32L463.54,24.86L466.03,14.66L467.45,16.59L467.81,13.5L468.16,16.03L468.52,22.98L470.3,66.83L470.65,94.26L471.01,99.06L472.07,73.17L472.43,90.31L472.78,66.17L474.56,142.84L474.92,117.22L475.63,198L475.98,155.71L477.05,221.89L477.41,195.56L478.47,239.09L479.54,252.02L480.6,180.72L480.96,197.63L482.03,181.91L482.38,189.86L482.74,211.73L483.09,201.29L483.45,208.5L485.58,153.64L487,158.92L487.36,143.41L487.71,155.23L488.07,152.22L488.43,138.42L489.49,148.09L489.85,164.48L490.2,152.92L490.56,153.2L491.98,138.29L492.34,141.1L492.69,127.12L493.05,132.18L493.4,147.61L494.47,145.37L494.82,140.61L495.18,144.35L495.53,138.29L495.89,129.32L496.96,129.25L497.67,149.94L498.02,143.93L498.38,141.86L500.16,122.16L500.51,126.47L502.29,118.48L502.64,110.3\" style=\"vector-effect: non-scaling-stroke; fill: none; stroke: rgb(238, 118, 0); stroke-opacity: 1; stroke-width: 1.3px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(141.14,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">2017</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(270.89,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">2018</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(400.64,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">2019</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(530.39,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">2020</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,342.53999999999996)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">1</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,299.37)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">1.1</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,256.21000000000004)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">1.2</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,213.04000000000002)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">1.3</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,169.88)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">1.4</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,126.72)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">1.5</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-7d28a8\"><g class=\"clips\"/><clipPath id=\"legend7d28a8\"><rect width=\"95\" height=\"48\" x=\"0\" y=\"0\"/></clipPath></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"legend\" pointer-events=\"all\" transform=\"translate(593.0600000000001, 100)\"><rect class=\"bg\" shape-rendering=\"crispEdges\" width=\"95\" height=\"48\" x=\"0\" y=\"0\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: rgb(255, 255, 255); fill-opacity: 1; stroke-width: 0px;\"/><g class=\"scrollbox\" transform=\"translate(0, 0)\" clip-path=\"url('#legend7d28a8')\"><g class=\"groups\"><g class=\"traces\" transform=\"translate(0, 14.5)\" style=\"opacity: 1;\"><text class=\"legendtext user-select-none\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">portfolio</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(0, 128, 240); stroke-opacity: 1; stroke-width: 1.3px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" pointer-events=\"all\" x=\"0\" y=\"-9.5\" width=\"89.984375\" height=\"19\" style=\"cursor: pointer; fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(0, 33.5)\" style=\"opacity: 1;\"><text class=\"legendtext user-select-none\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(77, 86, 99); fill-opacity: 1; white-space: pre;\">S&amp;P500</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(238, 118, 0); stroke-opacity: 1; stroke-width: 1.3px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" pointer-events=\"all\" x=\"0\" y=\"-9.5\" width=\"89.984375\" height=\"19\" style=\"cursor: pointer; fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g></g><rect class=\"scrollbar\" rx=\"20\" ry=\"3\" width=\"0\" height=\"0\" x=\"0\" y=\"0\" style=\"fill: rgb(128, 139, 164); fill-opacity: 1;\"/></g><g class=\"g-gtitle\"/><g class=\"g-xtitle\"><text class=\"xtitle\" x=\"331.5\" y=\"410.20625\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(77, 86, 99); opacity: 1; font-weight: normal; white-space: pre;\">Time</text></g><g class=\"g-ytitle\"><text class=\"ytitle\" transform=\"rotate(-90,34.575,235)\" x=\"34.575\" y=\"235\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(77, 86, 99); opacity: 1; font-weight: normal; white-space: pre;\">Cumulative Gross Return</text></g><g class=\"annotation\" data-index=\"0\" style=\"opacity: 1;\"><g class=\"annotation-text-g\" transform=\"rotate(0,487.14,288.1)\"><g class=\"cursor-pointer\" transform=\"translate(452, 279)\"><rect class=\"bg\" x=\"0.5\" y=\"0.5\" width=\"70\" height=\"17\" style=\"stroke-width: 1px; stroke: rgb(0, 0, 0); stroke-opacity: 0; fill: rgb(240, 248, 255); fill-opacity: 1;\"/><text class=\"annotation-text\" text-anchor=\"middle\" x=\"35.390625\" y=\"14\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\"><tspan style=\"font-weight:bold\">SR=0.768<tspan style=\"font-weight:bold\"></tspan></tspan></text></g></g></g><g class=\"annotation\" data-index=\"1\" style=\"opacity: 1;\"><g class=\"annotation-text-g\" transform=\"rotate(0,491.70000000000005,307)\"><g class=\"cursor-pointer\" transform=\"translate(451, 298)\"><rect class=\"bg\" x=\"0.5\" y=\"0.5\" width=\"81\" height=\"17\" style=\"stroke-width: 1px; stroke: rgb(0, 0, 0); stroke-opacity: 0; fill: rgb(240, 248, 255); fill-opacity: 1;\"/><text class=\"annotation-text\" text-anchor=\"middle\" x=\"41.1875\" y=\"14\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\"><tspan style=\"font-weight:bold\">MDD=9.1%<tspan style=\"font-weight:bold\"></tspan></tspan></text></g></g></g><g class=\"annotation\" data-index=\"2\" style=\"opacity: 1;\"><g class=\"annotation-text-g\" transform=\"rotate(0,479.595,109)\"><g class=\"cursor-pointer\" transform=\"translate(444, 100)\"><rect class=\"bg\" x=\"0.5\" y=\"0.5\" width=\"70\" height=\"17\" style=\"stroke-width: 1px; stroke: rgb(0, 0, 0); stroke-opacity: 0; fill: rgb(255, 235, 205); fill-opacity: 1;\"/><text class=\"annotation-text\" text-anchor=\"middle\" x=\"35.390625\" y=\"14\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\"><tspan style=\"font-weight:bold\">SR=0.379<tspan style=\"font-weight:bold\"></tspan></tspan></text></g></g></g><g class=\"annotation\" data-index=\"3\" style=\"opacity: 1;\"><g class=\"annotation-text-g\" transform=\"rotate(0,487.20000000000005,127.89999999999999)\"><g class=\"cursor-pointer\" transform=\"translate(442, 119)\"><rect class=\"bg\" x=\"0.5\" y=\"0.5\" width=\"90\" height=\"17\" style=\"stroke-width: 1px; stroke: rgb(0, 0, 0); stroke-opacity: 0; fill: rgb(255, 235, 205); fill-opacity: 1;\"/><text class=\"annotation-text\" text-anchor=\"middle\" x=\"45.453125\" y=\"14\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\"><tspan style=\"font-weight:bold\">MDD=36.1%<tspan style=\"font-weight:bold\"></tspan></tspan></text></g></g></g></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter s&p500 returns on test set dates\n",
    "snp_ret_test = snp_ret.loc[snp_ret.index.intersection(test_y_pred.index)]\n",
    "snp_cum_ret_test = np.cumprod(snp_ret_test+1) \n",
    "snp_cum_ret_test.columns=[\"S&P500\"]\n",
    "\n",
    "# 3Mtbill (risk-free rate) load\n",
    "date_parser = lambda x: pd.datetime.strptime(x, '%d/%m/%Y')\n",
    "tbill = pd.read_csv(\"3m_tbill_daily.csv\", index_col='date', date_parser=date_parser)\n",
    "tbill = tbill.applymap(lambda x: np.nan if x==\".\" else float(x))\n",
    "tbill.fillna(axis = 0, method=\"ffill\", inplace=True)\n",
    "tbill = tbill.applymap(lambda x: (x/100 + 1)**(1/252) -1)\n",
    "tbill = tbill.loc[snp_ret_test.index]\n",
    "\n",
    "# rank stocks by their predicted 1-day ahead return\n",
    "ranks = test_y_pred.rank(axis=1)\n",
    "\n",
    "# build top-(bottom-)5% long(short) positions based on ranks\n",
    "positions = ranks.apply(top_bottom_signal, axis=1, result_type=\"expand\")\n",
    "n_stock_traded = positions.applymap(lambda x: abs(x)).sum(axis=1)\n",
    "\n",
    "# build portfolio returns based on realized returns and positions taken\n",
    "portf = np.multiply(positions, test_y_all)\n",
    "portf_rets = portf.sum(axis=1)/n_stock_traded \n",
    "portf_cum_rets = pd.DataFrame(np.cumprod(portf_rets+1), columns=[\"portfolio\"])\n",
    "\n",
    "results = pd.concat([portf_cum_rets, snp_cum_ret_test], axis=1)\n",
    "\n",
    "# compute Sharpe Ratio and maximum drawdown for both strategies\n",
    "annual_sharpe_portfolio = sharpeRatio(portf_rets, tbill)\n",
    "annual_sharpe_sp        = sharpeRatio(snp_ret_test, tbill)\n",
    "mdd_portfolio = maximumDrawdown(portf_cum_rets)\n",
    "mdd_snp       = maximumDrawdown(snp_cum_ret_test)\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "fig = results.iplot(colorscale = \"polar\", xTitle = \"Time\", yTitle = \"Cumulative Gross Return\", \n",
    "                        theme=\"white\", asFigure=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis = {'showgrid': False}, yaxis = {'showgrid': False},\n",
    "    \n",
    "    annotations=[\n",
    "        dict(x=0.88, y=0.27, showarrow=False, \n",
    "             text=\"<b>SR={:1.3f}<b>\".format(annual_sharpe_portfolio), xref=\"paper\", yref=\"paper\", bgcolor=\"aliceblue\"),\n",
    "                 \n",
    "        dict(x=0.9, y=0.2, showarrow=False, \n",
    "             text=\"<b>MDD={:.1%}<b>\".format(mdd_portfolio), xref=\"paper\", yref=\"paper\", bgcolor=\"aliceblue\"),\n",
    "        \n",
    "        dict(x=0.865, y=1, showarrow=False, \n",
    "             text=\"<b>SR={:1.3f}<b>\".format(annual_sharpe_sp), xref=\"paper\", yref=\"paper\", bgcolor=\"blanchedalmond\"),\n",
    "        \n",
    "        dict(x=0.9, y=0.93, showarrow=False, \n",
    "                      text=\"<b>MDD={:.1%}<b>\".format(mdd_snp), xref=\"paper\", yref=\"paper\", bgcolor=\"blanchedalmond\"),\n",
    "                ]\n",
    "    \n",
    "                 )     \n",
    "\n",
    "fig.write_image(\"S&P_vs_portfolio.png\", format=\"png\")\n",
    "fig.show(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment to performance metrics\n",
    "The portfolio is clearly lagging S&P 500 over the 4-year period considered, excluding the recent crisis. However, it is way less volatile. The strategy provides a solid Sharpe Ratio of 0.768 (vs.0.379 for S&P500), with a maximum drawdown of 9.1% during the recent Covid crisis, much lower if compared to the huge drawdown in S&P500 (-36.1% between 20th February 2020 and 23rd March 2020). \n",
    "\n",
    "## Conclusion\n",
    "The study is by no mean exhaustive and does not constitute trading advice. To be more realistic, transaction costs should be taken into account. Moreover, feasiblity of the trades in proximity of market closing time should be assessed. In addition,  a more structured hyperparameter tuning might deliver better results. Nevertheless, We believe it is an interesting starting point for the exploration of more sophisticated trading strategies and the possible application in other asset classes. \n",
    "\n",
    "## References\n",
    "Chinco, A., Clark-Joseph, A. D., & Ye, M. (2019). Sparse Signals in the Cross-Section of Returns. _Journal of Finance_. https://doi.org/10.1111/jofi.12733\n",
    "\n",
    "Gu, S., Kelly, B. & Xiu, D. (2020) Empirical Asset Pricing via Machine Learning. _The Review of Financial Studies_. 33 (5), 2223-2273.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
